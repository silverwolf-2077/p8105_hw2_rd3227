---
title: "p8105_hw2_rd3227"
author: "Ruihan Ding"
date: "2025-09-29"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(haven)
library(lubridate)
```

# Problem 1

Clean the data in pols-month.csv

```{r}
# import dataset
pols_df = 
  read_csv(
    "fivethirtyeight/pols-month.csv", 
    na = c("NA", ".", ""), 
    show_col_types = FALSE
    ) |> 
  janitor::clean_names() |> 
  
# break up the variable mon into integer variables year, month, and day
  separate(
    mon, into = c("year", "month", "day"), sep = "-",
  ) |> 
  mutate(across(c(year:day), as.integer)) |> 

# replace month number with month name
  mutate(month = factor(month.name[month], levels = month.name)) |> 

# create a president variable
  mutate(
    president = case_when(
      prez_gop == 1 ~ "dem",
      prez_dem == 1 ~ "gop"
    )) |> 

# remove unnecessary columns
  select(-prez_gop, -prez_dem, -day)

```

Clean the data in snp.csv

```{r}
# import dataset
snp_df = 
  read_csv(
    "fivethirtyeight/snp.csv", 
    na = c("NA", ".", ""),
    show_col_types = FALSE
    ) |> 
  janitor::clean_names() |> 

# match the year and month format to the previous dataframe
  separate(
    date, into = c("month", "day", "year"), sep = "/",
  ) |> 
  mutate(across(c(month:year), as.integer)) |> 
  mutate(month = factor(month.name[month], levels = month.name)) |> 
  mutate(
    year = if_else(year < 20, 2000 + year, 1900 + year)) |> 

# arrange and organize
  select(year, month, everything(), -day) |> 
  arrange(year, month)

```

Clean the data in unemployment.csv

```{r}
# import dataset
unepm_df = 
  read_csv(
    "fivethirtyeight/unemployment.csv", 
    na = c("NA", ".", ""),
    show_col_types = FALSE
    ) |> 
  janitor::clean_names() |> 

# make month a factor variable
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) |> 
  mutate(
    month = factor(
    str_to_title(month), 
    levels = month.abb,
    labels = month.name
      )) |> 

# arrange according to time
  arrange(year, month) 

```

Join the datasets.

```{r}
merge_df = 
  left_join(pols_df, snp_df, by = c("year", "month")) |> 
  left_join(unepm_df, by = c("year", "month"))

```

The pols-month dataset contains 822 observations of 9 variables, covering monthly political data from 1947–2015. Variables include indicators of the president’s party (`prez_gop`, `prez_dem`) and counts of governors, senators, and representatives by party (`gov_gop`, `gov_dem`, `sen_gop`, `sen_dem`, `rep_gop`, `rep_dem`). The unemployment dataset has 68 observations of 13 variables, reporting monthly unemployment rates from 1948–2015, with one row per year (`year`) and twelve monthly columns (`Jan`–`Dec`). The snp dataset includes 787 observations of 2 variables, covering monthly closing values of the S&P 500 stock index (`date`, `close`) from 1950–2015. After merging these datasets by year and month, the resulting dataset spans 1950–2015, with `r nrow(merge_df)` rows × `r ncol(merge_df)` columns, and combines political indicators, unemployment rates, and stock market performance in a single table.

# Problem 2

Read and clean the Mr. Trash Wheel sheet.

```{r}
mtw_df = 
  read_excel("202509TrashWheel.xlsx", 
             sheet = "Mr. Trash Wheel", 
             range = "A2:N710", 
             na = c(""),
             ) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(year = as.integer(year)) |>
  mutate(
    sports_balls = as.integer(round(sports_balls))) |> 
  mutate(trash_wheel = "mr_trash_wheel")

```

Read and clean the Professor Trash Wheel sheet.

```{r}
ptw_df = 
  read_excel("202509TrashWheel.xlsx", 
             sheet = "Professor Trash Wheel", 
             range = "A2:M135", 
             na = c(""),
             ) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(year = as.integer(year)) |>
  mutate(trash_wheel = "professor_trash_wheel")

```

Read and clean the Gwynnda Trash Wheel sheet.

```{r}
gtw_df = 
  read_excel("202509TrashWheel.xlsx", 
             sheet = "Gwynns Falls Trash Wheel", 
             range = "A2:L352", 
             na = c("")
             ) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(year = as.integer(year)) |>
  mutate(trash_wheel = "gwynnda_trash_wheel")

```

Combine datasets.

```{r}
tw_df =
  bind_rows(mtw_df, ptw_df, gtw_df) |> 
  select(trash_wheel, everything())

```

The combined dataset includes `r nrow(tw_df)` rows × `r ncol(tw_df)` columns of observations on the dumpster number, date of collection, amount of total litter and litter type for Mr. Trash Wheel, Professor Trash Wheel and Gwynnda Trash Wheel.  

```{r}
weight_ptw = 
  ptw_df |> 
  pull(weight_tons) |>
  sum(na.rm = TRUE)

cb_gtw = 
  tw_df |>
  filter(trash_wheel == "gwynnda_trash_wheel", year == 2022, month == "June") |>
  pull(cigarette_butts) |> 
  sum(na.rm = TRUE)

```

The total weight of trash collected by Professor Trash Wheel is `r weight_ptw` tons.

The total number of cigarette butts collected by Gwynnda in June of 2022 is `r cb_gtw`.

# Problem 3

Tidy the Zip Codes dataset.

```{r}
zip_df = 
  read_csv("zillow_data/Zip Codes.csv", na = c("NA")) |> 
  janitor::clean_names() |> 
  select(-file_date)

```

Tidy the Zillow dataset.

```{r}
zillow_df = 
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA")) |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = starts_with("x"),
    names_to = "date",
    names_prefix = "x",
    values_to = "zori"
  ) |> 
  mutate(
    date = as.Date(date, format = "%Y_%m_%d"),
    county = str_remove(county_name, " County")
  ) |> 
  select(everything(), zip_code = region_name, -county_name, -state_name)

```

Merge them

```{r}
final_df = 
  left_join(zillow_df, zip_df) |> 
  select(region_id, region_type, size_rank, zip_code, state, state_fips, city, county, county_fips, county_code, neighborhood, metro, date, zori) |> 
  arrange(region_id, date)
  
```

The final dataset has `r nrow(final_df)` observations. `r nrow(distinct(final_df, zip_code))` unique ZIP codes and `r filter(final_df, !is.na(neighborhood)) |> distinct(neighborhood) |> nrow()` unique neighborhoods are included.

```{r}
missing_zip = 
  anti_join(zip_df, zillow_df, by = "zip_code") |> 
  distinct(zip_code) |> 
  mutate(zip_code = as.character(zip_code))
  
```

`r nrow(missing_zip)` ZIP codes appear in the ZIP code dataset but not in the Zillow Rental Price dataset, such as `r head(missing_zip$zip_code)`.

Make a table showing ZIP codes with largest drop in price from January 2020 to 2021.

```{r}
fluc_df = 
  final_df |> 
  filter(
   month(date) == 1,
   year(date) %in% c(2020, 2021),
   !is.na(zip_code),
   !is.na(zori)
  ) |> 
  select(zip_code, county, neighborhood, date, zori) |> 
  pivot_wider(
    names_from = date,
    values_from = zori
  ) |> 
  mutate(
    drop = `2020-01-31` - `2021-01-31`
  ) |> 
  filter(!is.na(drop)) |> 
  arrange(desc(drop))

top10_drop = 
  fluc_df |> 
  slice_head(n = 10)

knitr::kable(top10_drop)
```





