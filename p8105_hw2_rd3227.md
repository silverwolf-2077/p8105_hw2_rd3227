p8105_hw2_rd3227
================
Ruihan Ding
2025-09-29

# Problem 1

Clean the data in pols-month.csv

``` r
# import dataset
pols_df = 
  read_csv(
    "fivethirtyeight/pols-month.csv", 
    na = c("NA", ".", ""), 
    show_col_types = FALSE
    ) |> 
  janitor::clean_names() |> 
  
# break up the variable mon into integer variables year, month, and day
  separate(
    mon, into = c("year", "month", "day"), sep = "-",
  ) |> 
  mutate(across(c(year:day), as.integer)) |> 

# replace month number with month name
  mutate(month = factor(month.name[month], levels = month.name)) |> 

# create a president variable
  mutate(
    president = case_when(
      prez_gop == 1 ~ "dem",
      prez_dem == 1 ~ "gop"
    )) |> 

# remove unnecessary columns
  select(-prez_gop, -prez_dem, -day)
```

Clean the data in snp.csv

``` r
# import dataset
snp_df = 
  read_csv(
    "fivethirtyeight/snp.csv", 
    na = c("NA", ".", ""),
    show_col_types = FALSE
    ) |> 
  janitor::clean_names() |> 

# match the year and month format to the previous dataframe
  separate(
    date, into = c("month", "day", "year"), sep = "/",
  ) |> 
  mutate(across(c(month:year), as.integer)) |> 
  mutate(month = factor(month.name[month], levels = month.name)) |> 
  mutate(
    year = if_else(year < 20, 2000 + year, 1900 + year)) |> 

# arrange and organize
  select(year, month, everything(), -day) |> 
  arrange(year, month)
```

Clean the data in unemployment.csv

``` r
# import dataset
unepm_df = 
  read_csv(
    "fivethirtyeight/unemployment.csv", 
    na = c("NA", ".", ""),
    show_col_types = FALSE
    ) |> 
  janitor::clean_names() |> 

# make month a factor variable
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) |> 
  mutate(
    month = factor(
    str_to_title(month), 
    levels = month.abb,
    labels = month.name
      )) |> 

# arrange according to time
  arrange(year, month) 
```

Join the datasets.

``` r
merge_df = 
  left_join(pols_df, snp_df, by = c("year", "month")) |> 
  left_join(unepm_df, by = c("year", "month"))
```

The pols-month dataset contains 822 observations of 9 variables,
covering monthly political data from 1947–2015. Variables include
indicators of the president’s party (`prez_gop`, `prez_dem`) and counts
of governors, senators, and representatives by party (`gov_gop`,
`gov_dem`, `sen_gop`, `sen_dem`, `rep_gop`, `rep_dem`). The unemployment
dataset has 68 observations of 13 variables, reporting monthly
unemployment rates from 1948–2015, with one row per year (`year`) and
twelve monthly columns (`Jan`–`Dec`). The snp dataset includes 787
observations of 2 variables, covering monthly closing values of the S&P
500 stock index (`date`, `close`) from 1950–2015. After merging these
datasets by year and month, the resulting dataset spans 1950–2015, with
822 rows × 11 columns, and combines political indicators, unemployment
rates, and stock market performance in a single table.

# Problem 2

Read and clean the Mr. Trash Wheel sheet.

``` r
mtw_df = 
  read_excel("202509TrashWheel.xlsx", 
             sheet = "Mr. Trash Wheel", 
             range = "A2:N710", 
             na = c(""),
             ) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(year = as.integer(year)) |>
  mutate(
    sports_balls = as.integer(round(sports_balls))) |> 
  mutate(trash_wheel = "mr_trash_wheel")
```

Read and clean the Professor Trash Wheel sheet.

``` r
ptw_df = 
  read_excel("202509TrashWheel.xlsx", 
             sheet = "Professor Trash Wheel", 
             range = "A2:M135", 
             na = c(""),
             ) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(year = as.integer(year)) |>
  mutate(trash_wheel = "professor_trash_wheel")
```

Read and clean the Gwynnda Trash Wheel sheet.

``` r
gtw_df = 
  read_excel("202509TrashWheel.xlsx", 
             sheet = "Gwynns Falls Trash Wheel", 
             range = "A2:L352", 
             na = c("")
             ) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(year = as.integer(year)) |>
  mutate(trash_wheel = "gwynnda_trash_wheel")
```

Combine datasets.

``` r
tw_df =
  bind_rows(mtw_df, ptw_df, gtw_df) |> 
  select(trash_wheel, everything())
```

The combined dataset includes 1188 rows × 15 columns of observations on
the dumpster number, date of collection, amount of total litter and
litter type for Mr. Trash Wheel, Professor Trash Wheel and Gwynnda Trash
Wheel.

``` r
weight_ptw = 
  ptw_df |> 
  pull(weight_tons) |>
  sum(na.rm = TRUE)

cb_gtw = 
  tw_df |>
  filter(trash_wheel == "gwynnda_trash_wheel", year == 2022, month == "June") |>
  pull(cigarette_butts) |> 
  sum(na.rm = TRUE)
```

The total weight of trash collected by Professor Trash Wheel is 282.26
tons.

The total number of cigarette butts collected by Gwynnda in June of 2022
is 1.812^{4}.

# Problem 3

Tidy the Zip Codes dataset.

``` r
zip_df = 
  read_csv("zillow_data/Zip Codes.csv", na = c("NA")) |> 
  janitor::clean_names() |> 
  select(-file_date)
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Tidy the Zillow dataset.

``` r
zillow_df = 
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA")) |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = starts_with("x"),
    names_to = "date",
    names_prefix = "x",
    values_to = "zori"
  ) |> 
  mutate(
    date = as.Date(date, format = "%Y_%m_%d"),
    county = str_remove(county_name, " County")
  ) |> 
  select(everything(), zip_code = region_name, -county_name, -state_name)
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Merge them

``` r
final_df = 
  left_join(zillow_df, zip_df) |> 
  select(region_id, region_type, size_rank, zip_code, state, state_fips, city, county, county_fips, county_code, neighborhood, metro, date, zori) |> 
  arrange(region_id, date)
```

    ## Joining with `by = join_by(zip_code, county)`

The final dataset has 17284 observations. 149 unique ZIP codes and 42
unique neighborhoods are included.

``` r
missing_zip = 
  anti_join(zip_df, zillow_df, by = "zip_code") |> 
  distinct(zip_code) |> 
  mutate(zip_code = as.character(zip_code))
```

171 ZIP codes appear in the ZIP code dataset but not in the Zillow
Rental Price dataset, such as 10464, 10474, 10475, 10499, 10550, 10704.

Make a table showing ZIP codes with largest drop in price from January
2020 to 2021.

``` r
fluc_df = 
  final_df |> 
  filter(
   month(date) == 1,
   year(date) %in% c(2020, 2021),
   !is.na(zip_code),
   !is.na(zori)
  ) |> 
  select(zip_code, county, neighborhood, date, zori) |> 
  pivot_wider(
    names_from = date,
    values_from = zori
  ) |> 
  mutate(
    drop = `2020-01-31` - `2021-01-31`
  ) |> 
  filter(!is.na(drop)) |> 
  arrange(desc(drop))

top10_drop = 
  fluc_df |> 
  slice_head(n = 10)

knitr::kable(top10_drop)
```

| zip_code | county | neighborhood | 2020-01-31 | 2021-01-31 | drop |
|---:|:---|:---|---:|---:|---:|
| 10007 | New York | Lower Manhattan | 6334.211 | 5421.614 | 912.5966 |
| 10069 | New York | NA | 4623.042 | 3874.918 | 748.1245 |
| 10009 | New York | Lower East Side | 3406.442 | 2692.187 | 714.2550 |
| 10016 | New York | Gramercy Park and Murray Hill | 3731.135 | 3019.431 | 711.7045 |
| 10001 | New York | Chelsea and Clinton | 4108.098 | 3397.648 | 710.4499 |
| 10002 | New York | Lower East Side | 3645.416 | 2935.113 | 710.3028 |
| 10004 | New York | Lower Manhattan | 3149.658 | 2443.697 | 705.9608 |
| 10038 | New York | Lower Manhattan | 3573.201 | 2875.616 | 697.5853 |
| 10012 | New York | Greenwich Village and Soho | 3628.566 | 2942.344 | 686.2218 |
| 10010 | New York | Gramercy Park and Murray Hill | 3697.284 | 3012.353 | 684.9304 |
